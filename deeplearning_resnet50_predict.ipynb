{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2863,"status":"ok","timestamp":1673447644644,"user":{"displayName":"Draw","userId":"17173715679863169492"},"user_tz":-480},"id":"ZqPyb2XI-i0N"},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","from torchvision import transforms, datasets\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n","from torchvision.models import resnet18, resnet50, resnet101, resnet152\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LmOxECk3wqCj","outputId":"cfb2df1c-a8ed-44b2-ac21-d5d316cd51dc","executionInfo":{"status":"ok","timestamp":1673447664181,"user_tz":-480,"elapsed":19543,"user":{"displayName":"Draw","userId":"17173715679863169492"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"YhG3ykEEUAF4","executionInfo":{"status":"ok","timestamp":1673447664182,"user_tz":-480,"elapsed":11,"user":{"displayName":"Draw","userId":"17173715679863169492"}}},"outputs":[],"source":["def calc_acc(output, target):\n","    predicted = torch.max(output, 1)[1]\n","    num_samples = target.size(0)\n","    num_correct = (predicted == target).sum().item()\n","    return num_correct / num_samples"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"7h8N1IWYUADJ","executionInfo":{"status":"ok","timestamp":1673447664183,"user_tz":-480,"elapsed":11,"user":{"displayName":"Draw","userId":"17173715679863169492"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Fw7DpUg_UAA5","executionInfo":{"status":"ok","timestamp":1673447664184,"user_tz":-480,"elapsed":12,"user":{"displayName":"Draw","userId":"17173715679863169492"}}},"outputs":[],"source":["def validation(model, device, valid_loader, criterion):\n","    # ===============================\n","    # TODO 6: switch the model to validation mode\n","    model.eval()\n","    # ===============================\n","    valid_acc = 0.0\n","    valid_loss = 0.0\n","\n","    # =========================================\n","    # TODO 7: turn off the gradient calculation\n","    with torch.set_grad_enabled(False):\n","    # =========================================\n","        for data, target in tqdm(valid_loader):\n","            data, target = data.to(device), target.to(device)\n","\n","            output = model(data)\n","\n","            # ================================\n","            # TODO 8: calculate accuracy, loss\n","            loss = criterion(output, target)\n","            valid_loss += loss.item()\n","            valid_acc += calc_acc(output, target)\n","            # ================================\n","\n","    valid_acc /= len(valid_loader)\n","    valid_loss /= len(valid_loader)\n","\n","    return valid_acc, valid_loss"]},{"cell_type":"code","source":["\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","torch.cuda.memory_summary(device=None, abbreviated=False)"],"metadata":{"id":"iqjCzCiXtqUj","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1673447664579,"user_tz":-480,"elapsed":406,"user":{"displayName":"Draw","userId":"17173715679863169492"}},"outputId":"08d19ccc-34b9-4927-f8e9-9a39a87846e1"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Resize to 224*224"],"metadata":{"id":"b5iTbn6dMhUN"}},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","# 原本切割好的檔案路徑\n","origin_path = '/content/drive/MyDrive/Colab Notebooks/project/training_224/test_cut'\n","# resize成224的檔案路徑\n","resized_path = '/content/drive/MyDrive/Colab Notebooks/project/training_224/resized_cut'\n","ext = '.png'\n","def cv_imread(filepath):\n","    cv_img = cv2.imdecode(np.fromfile(filepath, dtype=np.uint8), -1)\n","    # cv_img=cv2.cvtColor(cv_img, cv2.COLOR_RGB2BGR)\n","    return cv_img\n","\n","print('start converting...')\n","\n","# from_dir_path = os.path.join(origin_path, str(1))\n","to_dir_path = os.path.join(resized_path)\n","os.makedirs(to_dir_path, exist_ok=True)\n","\n","pics = sorted(os.listdir(origin_path))\n","# print(pics)\n","# print(f'number[{i}] pictures = {len(pics)}')\n","\n","for i, pic in enumerate(pics):\n","    print(f'i={i},pic={pic}')\n","    from_path = os.path.join(origin_path, pic)\n","    to_path = os.path.join(to_dir_path, f'{i}{ext}')\n","\n","    image = cv_imread(from_path)\n","    image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n","    cv2.imwrite(to_path, image)"],"metadata":{"id":"kSwuxtxh6brz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673447689517,"user_tz":-480,"elapsed":25342,"user":{"displayName":"Draw","userId":"17173715679863169492"}},"outputId":"e71c9230-a255-43dc-f51f-779a82bd89a9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["start converting...\n","i=0,pic=Pic_1.png\n","i=1,pic=Pic_10.png\n","i=2,pic=Pic_11.png\n","i=3,pic=Pic_12.png\n","i=4,pic=Pic_13.png\n","i=5,pic=Pic_14.png\n","i=6,pic=Pic_15.png\n","i=7,pic=Pic_16.png\n","i=8,pic=Pic_17.png\n","i=9,pic=Pic_18.png\n","i=10,pic=Pic_19.png\n","i=11,pic=Pic_2.png\n","i=12,pic=Pic_20.png\n","i=13,pic=Pic_21.png\n","i=14,pic=Pic_22.png\n","i=15,pic=Pic_23.png\n","i=16,pic=Pic_24.png\n","i=17,pic=Pic_25.png\n","i=18,pic=Pic_26.png\n","i=19,pic=Pic_27.png\n","i=20,pic=Pic_28.png\n","i=21,pic=Pic_29.png\n","i=22,pic=Pic_3.png\n","i=23,pic=Pic_30.png\n","i=24,pic=Pic_31.png\n","i=25,pic=Pic_32.png\n","i=26,pic=Pic_33.png\n","i=27,pic=Pic_34.png\n","i=28,pic=Pic_35.png\n","i=29,pic=Pic_36.png\n","i=30,pic=Pic_37.png\n","i=31,pic=Pic_38.png\n","i=32,pic=Pic_39.png\n","i=33,pic=Pic_4.png\n","i=34,pic=Pic_40.png\n","i=35,pic=Pic_41.png\n","i=36,pic=Pic_42.png\n","i=37,pic=Pic_5.png\n","i=38,pic=Pic_6.png\n","i=39,pic=Pic_7.png\n","i=40,pic=Pic_8.png\n","i=41,pic=Pic_9.png\n"]}]},{"cell_type":"markdown","source":["Set model & device"],"metadata":{"id":"5ywlB2UsNUVR"}},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","model = resnet18(pretrained=False)\n","model.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","model.fc = nn.Linear(in_features=model.fc.in_features, out_features=1000, bias=True)\n","BATCH_SIZE=32"],"metadata":{"id":"KVe65-u3dco2","executionInfo":{"status":"ok","timestamp":1673447689916,"user_tz":-480,"elapsed":414,"user":{"displayName":"Draw","userId":"17173715679863169492"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bacba3ad-a0e7-4750-de76-d5cef81e30f8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"markdown","source":["Predict acc (可略)"],"metadata":{"id":"k3FSFaWXNcBg"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","# pt檔案\n","MODEL_PT = '/content/drive/MyDrive/Colab Notebooks/project/training_224/model/Resnet18_5.pt'\n","model.load_state_dict(torch.load(MODEL_PT, map_location=torch.device('cpu')))\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","dict_label = {}\n","\n","LEARNING_RATE = 0.0001\n","BATCH_SIZE =32\n","EPOCHS = 100\n","# 有用資料夾標記label的resized224檔案\n","VALID_DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/project/training_224/resized_224_2'\n","\n","DOWNLOAD_MNIST = False\n","\n","\n","valid_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","valid_data = datasets.ImageFolder(VALID_DATA_PATH, transform=valid_transform)\n","valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n","\n","# model = resnet.to(device).train()\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=-1)\n","# optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.98)\n","\n","test_acc, test_loss = validation(model, device, valid_loader, criterion)\n","print(f'test_acc={test_acc*100}% test_loss={test_loss}')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"id":"oubNi6rbPEpn","executionInfo":{"status":"error","timestamp":1673447707398,"user_tz":-480,"elapsed":17485,"user":{"displayName":"Draw","userId":"17173715679863169492"}},"outputId":"26750e48-7af9-4019-e43a-b06e80097f5b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/1 [00:11<?, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-e626f629c2db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.98)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'test_acc={test_acc*100}% test_loss={test_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-a074828e6a37>\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(model, device, valid_loader, criterion)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# ================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"]}]},{"cell_type":"markdown","source":["Predict label"],"metadata":{"id":"DLp1qgXRNjpJ"}},{"cell_type":"code","source":["from PIL import Image\n","import os\n","import cv2\n","import numpy as np\n","\n","# resize成224的檔案路徑\n","TEST_DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/project/training_224/resized_cut'\n","\n","img_path = os.path.join(TEST_DATA_PATH)\n","\n","pics = sorted(os.listdir(img_path))\n","\n","for i, pic in enumerate(pics):\n","\n","  img_path2 = os.path.join(img_path, pic)\n","\n","  img = Image.open(img_path2)\n","\n","  # Transform\n","  input = valid_transform(img)\n","\n","  # unsqueeze batch dimension, in case you are dealing with a single image\n","  # input = input.unsquueeze(0)\n","\n","  # Set model to eval\n","  model.eval()\n","\n","  input = input.view(1, 3, 224, 224)\n","\n","  # Get prediction\n","  output = model(input)\n","\n","  # vector = np.vectorize(np.int_)\n","  prediction = int(torch.max(output.data, 1)[1].numpy())+1\n","  print(f'{pic}={prediction}')\n","  dict_label[pic] = prediction\n"],"metadata":{"id":"xUAUjqo8NgTi","executionInfo":{"status":"aborted","timestamp":1673447707400,"user_tz":-480,"elapsed":13,"user":{"displayName":"Draw","userId":"17173715679863169492"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Convert to csv"],"metadata":{"id":"ItjLodH2Nn-W"}},{"cell_type":"code","source":["import csv\n","# label存成csv的路徑\n","CSV_PATH = '/content/drive/MyDrive/Colab Notebooks/project/training_224/csv/predict.csv'\n","# 開啟輸出的 CSV 檔案\n","with open(CSV_PATH, 'w', encoding = 'utf-8-sig') as csvfile:\n","  # 建立 CSV 檔寫入器\n","  writer = csv.writer(csvfile)\n","  writer.writerow(['pic', 'predict_label'])\n","  for key in dict_label:\n","  # 寫入一列資料\n","    writer.writerow([key, dict_label[key]])\n"],"metadata":{"id":"BM_RBA7FNVs-","executionInfo":{"status":"aborted","timestamp":1673447707400,"user_tz":-480,"elapsed":13,"user":{"displayName":"Draw","userId":"17173715679863169492"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"bJY88APrvsr3","executionInfo":{"status":"aborted","timestamp":1673447707401,"user_tz":-480,"elapsed":14,"user":{"displayName":"Draw","userId":"17173715679863169492"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1hyv0gwkViSPham2H3BLrGreuN-MnVmf0","timestamp":1667398156300}],"mount_file_id":"1hyv0gwkViSPham2H3BLrGreuN-MnVmf0","authorship_tag":"ABX9TyMag5GsUbxT63JUGznsSg3D"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}